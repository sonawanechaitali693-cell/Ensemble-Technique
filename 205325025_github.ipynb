{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "v_iRxd67HH6C",
        "outputId": "389e6177-69dd-4d30-b2bf-f1bc466956b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 398, Testing samples: 171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize the single Decision Tree Classifier\n",
        "tree_model = DecisionTreeClassifier(random_state=42, max_depth=4)\n",
        "\n",
        "# 2. Train the model\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Predict and evaluate\n",
        "y_pred_tree = tree_model.predict(X_test)\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "\n",
        "print(f\"Single Decision Tree Accuracy: {accuracy_tree:.4f}\")"
      ],
      "metadata": {
        "id": "Kqgh4AS4Humn",
        "outputId": "3d35e307-a250-46a9-fa8f-5eb8fd04152c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Decision Tree Accuracy: 0.9532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize the XGBoost Classifier\n",
        "# n_estimators=100 is the number of trees (boosting rounds)\n",
        "# learning_rate controls how much each tree 'corrects' the error\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False, # Suppresses a common warning\n",
        "    eval_metric='logloss',   # Sets the evaluation metric for classification\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2. Train the ensemble model (Boosting)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Predict and evaluate\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(f\"XGBoost (Ensemble) Accuracy: {accuracy_xgb:.4f}\")"
      ],
      "metadata": {
        "id": "UqSFUK7pIYTh",
        "outputId": "596bc785-2dd3-4d64-8fc0-56e6b94cb36f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost (Ensemble) Accuracy: 0.9591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [07:05:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4391adf",
        "outputId": "195dcbb6-638f-47dc-edf8-547e64146556"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset (Binary Classification)\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 1. Initialize the single Decision Tree Classifier\n",
        "tree_model = DecisionTreeClassifier(random_state=42, max_depth=4)\n",
        "\n",
        "# 2. Train the model\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Predict and evaluate\n",
        "y_pred_tree = tree_model.predict(X_test)\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "\n",
        "# 1. Initialize the XGBoost Classifier\n",
        "# n_estimators=100 is the number of trees (boosting rounds)\n",
        "# learning_rate controls how much each tree 'corrects' the error\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False, # Suppresses a common warning\n",
        "    eval_metric='logloss',   # Sets the evaluation metric for classification\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2. Train the ensemble model (Boosting)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Predict and evaluate\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(\"\\n## üèÜ Model Comparison\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Single Decision Tree Accuracy: {accuracy_tree:.4f}\")\n",
        "print(f\"XGBoost Ensemble Accuracy:     {accuracy_xgb:.4f}\")\n",
        "\n",
        "# Detailed report for the superior model (XGBoost)\n",
        "print(\"\\n## üîé XGBoost Classification Report\")\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=['Malignant', 'Benign']))\n",
        "\n",
        "# Visualize Feature Importance (A key insight from tree-based models)\n",
        "importance = xgb_model.feature_importances_\n",
        "feature_importances = pd.Series(importance, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "print(\"\\n## ‚ú® Top Feature Importances (Most Predictive Features)\")\n",
        "print(feature_importances.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## üèÜ Model Comparison\n",
            "------------------------------\n",
            "Single Decision Tree Accuracy: 0.9532\n",
            "XGBoost Ensemble Accuracy:     0.9591\n",
            "\n",
            "## üîé XGBoost Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Malignant       0.95      0.94      0.94        63\n",
            "      Benign       0.96      0.97      0.97       108\n",
            "\n",
            "    accuracy                           0.96       171\n",
            "   macro avg       0.96      0.95      0.96       171\n",
            "weighted avg       0.96      0.96      0.96       171\n",
            "\n",
            "\n",
            "## ‚ú® Top Feature Importances (Most Predictive Features)\n",
            "mean concave points     0.467806\n",
            "worst concave points    0.136023\n",
            "worst perimeter         0.057378\n",
            "worst radius            0.046021\n",
            "worst area              0.030302\n",
            "dtype: float32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [09:56:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LwJs679GmGa"
      },
      "outputs": [],
      "source": [
        "# Install XGBoost (if needed)\n",
        "!pip install xgboost -qq\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset (Binary Classification)\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "print(\"Breast Cancer Dataset Loaded Successfully!\")\n",
        "print(f\"Feature names: {list(X.columns)}\")"
      ]
    }
  ]
}